<!DOCTYPE html>
<html lang="it-IT">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Gesture Recognition with Arduino and MediaPiepe</title>
    <!-- Meta -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="D'Acunto Andrea - D'Emilio  Marco - Russo Vincenzo">
    <link rel="shortcut icon" href="https://mediapipe.dev/images/mediapipe_small.png">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-Zenh87qX5JnK2Jl0vWa8Ck2rdkQ2Bzep5IDxbcnCeuOxjzrPF/et3URy9Bv1WTRi" crossorigin="anonymous">
    <link id="theme-style" rel="stylesheet" href="./css/styles.css">

    <script src="./js/highlight.min.js"></script>
    <link rel="stylesheet" href="./css/styleprecode.min.css">
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
</head>

<body>
    <header class="header">
        <div class="container">
            <div class="row">
                <div class="col-md-8 align-self-center profile-content">
                    <img class="img-fluid  profile-image img-responsive pull-left" src="./assets/img/logo.svg"
                        alt="logo" hegiht="300" width="300">
                    <h1 class="name">Gesture classification and recognition with Arduino</h1>
                    <h2 class="desc">Creazione e sviluppo di un applicativo desktop per il riconoscimento
                        delle gesture della mano tramite
                        l'utilizzo di <strong>Mediapipe</strong> ed integrazione con Arduino </h2>
                </div>
                <div class="col-md-4">
                    <div class="profile-content pull-right">
                        <img class="profile-image img-responsive pull-left"
                            src="http://web.unibas.it/bloisi/assets/images/logo.png" alt="unibas logo" height=97
                            width=312 />
                        <p>&nbsp;</p>
                        <h3 class="desc">
                            <a href="http://web.unibas.it/bloisi/corsi/visione-e-percezione.html" target="_blank">
                                Corso di Visione e Percezione</a>
                        </h3>
                    </div>
                </div>
            </div>

        </div>
    </header>

    <div class="container sections-wrapper">
        <div class="row">
            <div class="primary col-md-8 col-sm-12 col-xs-12">
                <!-- Problema -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading">Problema</h2>
                        <div class="content">
                            <p>
                                Una problematica nota nel campo dei dispositivi smart consiste nella possibilità di
                                interagire con loro
                                attraverso varie opzioni, tra le più comuni vi è la voce per impartire comandi di
                                varia natura, il viso per il riconoscimento facciale oppure, di molto più interesse per
                                noi, l'utilizzo delle mani per il riconoscimento di gestures e segni. Il tutto è
                                finalizzato alla modifica del comportamento del dispositivo a seconda delle esigenze.
                            </p>
                        </div>
                    </div>
                </section>

                <!-- Motivazioni -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading">Motivazioni</h2>
                        <div class="content">
                            <p>
                                Il progetto posto in essere consiste nella detection e nella classificazione di hand
                                gesture per impartire comandi ai sensori di un arduino. Le motivazioni che ci hanno
                                portato a concentrare
                                i nostri sforzi nella realizzazione di un applicativo per la classificazione e il
                                controllo degli hand sign e delle hand
                                gestures è da attribuire alla loro utilità in diversi ambiti, come ad esempio quello
                                domestico (e.g, controllo di dispositivi smart come accendere le luci o alzare/abbassare
                                le tapparelle in maniera semplice e intuitiva).
                            </p>
                        </div>
                    </div>
                </section>

                <!-- Obiettivi -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="goals"></a>Obiettivi</h2>
                        <div class="content">
                            La realizzazione del seguente progetto consta di quatro parti:</br></br>
                            <ol>
                                <li><strong>Creazione</strong> dei datasets per la classificazione degli hand sign e 
                                    per le gestures della mano;</li>
                                <li><strong>Training</strong> dei modelli tramite i corrispettivi datasets;</li>
                                <li><strong>Implementazione</strong> di un applicativo grafico per la gestione delle
                                    gesture; </li>
                                <li><strong>Connessione</strong> con l'Arduino e invio dei comandi ai sensori.</li>
                            </ol>
                            </p>

                        </div>
                    </div>
                </section>

                <!-- Assemblaggio -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="assemblaggio"></a>Assemblaggio del circuito</h2>
                        <div class="content">

                            <p>Il processo di assemblaggio del circuito di Arduino, portato a termine tenendo in considerazione
                                l'insieme delle gestures da identificare, è finalizzato a garantirci la possibilità di simulare un ambiente reale.</p>
                            <p>I componenti usati per l'assemblaggio del circuito sono elencati di seguito: </p>
                            <ul>
                                <li>
                                    <strong>Microcontrollore:</strong> Arduino uno.
                                </li>
                                <li>
                                    <strong>Interfacciamento dei componenti:</strong>
                                </li>
                                <ol>
                                    <li>
                                        <p class="mb-0">Led: Rosso, Verde, Blu;</p>
                                    </li>
                                    <li>
                                        <p class="mb-0">Piezometro;</p>
                                    </li>
                                    <li>
                                        <p class="mb-0">Servo Motore.</p>
                                    </li>
                                </ol>
                            </ul>

                            <br>
                            <strong>Schema circuitale</strong>
                            <p>Nell'immagine sottostante viene mostrato lo schema circuitale seguito dall'assemblaggio
                                dei vari componenti. </p>
                            <div class="row">
                                <img class="d-flex justify-content-center" src="./assets/img/shemaArduino.svg" />
                            </div>
                            <br>
                            <br>
                            <strong>Utilizzo dei componenti</strong>
                            <p>I componenti sopra elencati, mediante l'integrazione con l'applicativo desktop, vengono
                                comandati tramite le gesture ad essi collegate:</p>
                            <ul>
                                <li>
                                    <p class="fw-bold mb-0">Led:</p>
                                    <p class="fw-italic mb-0">Comportamento "Singolo":</p>
                                    <ol>
                                        <li>
                                            <span style="color: #ff0000">Rosso</span>: si accende quando viene recepita
                                            la gesture che indica il numero due.
                                        </li>
                                        <li>
                                            <span style="color: #00af17">Verde</span>: si accende quando viene recepita
                                            la gesture che indica il numero tre.
                                        </li>
                                        <li>
                                            <span style="color: #0000ff">Blu</span>: si accende quando viene recepita la
                                            gesture che indica il numero quattro.
                                        </li>
                                    </ol>
                                    <br>
                                    <p class="fw-italic mb-0">Comportamento "Collaborativo":</p>
                                    <ul>
                                        <li>
                                            <p class="mb-0">Il riconoscimento della gesture <strong>Palm Open - mano aperta
                                                -</strong> comporta l'accensione contemporanea di tutti i led. </p>
                                        </li>
                                        <li>
                                            <p class="mb-0">Il riconoscimento della gesture <strong>First - mano chiusa
                                                -</strong> comporta lo spegnimento contemponeo di tutti i led. </p>
                                        </li>
                                    </ul>
                                    
                                    
                                </li>
                            </br>
                                <li>
                                    <p class="fw-bold mb-0">Piezometro:</p>
                                    <p class="mb-0">Il riconoscimento della gesture <strong>Palm Open - mano aperta -
                                        </strong> emette una nota che equivale al valore di 262.</p>
                                    <p class="mb-0">Il riconoscimento della gesture <strong>First - mano chiusa -
                                        </strong> emette una nota che equivale al valore di 294.</p>
                                </li>
                            </br>
                                <li>
                                    <p class="fw-bold mb-0">Servo Motore:</p>
                                    <p class="mb-0">Il riconoscimento della gesture <strong>Index - indice della mano
                                        </strong> in base al movimento che effettua - Rotazione senso
                                        orario oppure Rotazione senso antiorario - ruota il servo motore da 0° a 180°
                                        oppure da 180° a 0°.</p>
                                </li>
                            </ul>

                        </div>
                    </div>
                </section>

                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="dataset"></a>Metodo</h2>
                        <h3 class="h3-heading"> Hand detection</h3>
                        <div class="content">
                            <p>
                                Lo strumento utilizzato per effettuare la detection della mano è
                                <strong>Mediapipe</strong>, questa è una
                                soluzione di <i>Hand Traking</i> ad alta fedeltà. Utilizza il machine learning per
                                dedurre 21 punti di riferimento 3D
                                da un singolo fotogramma.
                                Mediapipe utilizza una pipeline composta da più modelli che lavorano insieme:
                            <ul>
                                <li>Un modello di rilevamento del palmo che opera sull'immagine completa e restituisce
                                    un riquadro di delimitazione della mano orientato;</li>
                                <li>Un modello di riferimento della mano che opera sulla regione della ROI(Region of
                                    Interest) definita precedentemente dal rilevatore del palmo e
                                    restituisce punti chiave della mano 3D ad alta fedeltà.</li>
                            </ul>
                            Dopo il rilevamento del palmo sull'intera immagine, il modello esegue una precisa
                            localizzazione
                            dei punti chiave composti da 21 coordinate 3D delle nocche della mano all'interno della ROI
                            rilevata tramite regressione.
                            Il modello apprende una rappresentazione coerente della posa della mano interna ed è robusto
                            anche per mani parzialmente
                            visibili.
                            </p>



                        </div>
                        <h3 class="h3-heading"> Creazione dataset <i>Hand sign</i></h3>
                        <div class="content">
                            <p>
                                In questa fase, la generazione del dataset ha richiesto la creazione di uno script in
                                Python per l'estrapolazione
                                dei Keypoint della mano <code>classification_gestures.py</code>.</br>
                                In particolare questo script, effettua la detection dei Keypoint con Mediapipe ed
                                estrapola
                                quest'ultimi in un file .csv che sarà usato come input per la fase di
                                training.</br></br>

                                <img class="img-fluid  profile-image img-responsive pull-left"
                                    src="./assets/img/hand_landmarks.png"> </br></br>

                                I dati estratti dai Landmarks, prima di essere inseriti nel file di dataset, vengono
                                preprocessati nel seguente modo:
                            <ul>
                                <li>Conversione delle coordinate relative all'ID:0 (punto di polso);</li>
                                <li>Conversione in un array mono dimensionale;</li>
                                <li>Normalizzazione rispetto ad un valore di massimo.</li>
                            </ul>

                            Eseguendo lo script con argomento <i>mode 1</i> si avrà il seguente:
                            </br></br><img class="img-fluid  profile-image img-responsive pull-left"
                                src="./assets/img/hand-sign.png"> </br></br>

                            Utilizzando i tasti numerici da "0" a "5", i Keypoints verranno aggiunti al file
                            <code>assets/dataset/keypoint.csv</code>
                            come mostrato di seguito.</br>
                            Prima colonna: numero della tastiera (utilizzato come l'ID della classe), dalla seconda
                            colonna in poi: coordinate dei Keypoints.</br></br>

                            <img class="img-fluid  profile-image img-responsive pull-left"
                                src="./assets/img/Dataset1.png">
                            </br></br>
                            </p>



                        </div>

                        <h3 class="h3-heading"> Creazione dataset <i>Hand gesture</i></h3>
                        <div class="content">
                            <p>
                                In questa fase, la generazione del dataset inerente alla classificazione delle hand
                                gestures ha richiesto l'estensione dello script
                                ,precedentemente introdotto, affinchè implementasse la classificazione del segno
                                <i>indice</i> e di conseguenza, l'estrazione del singolo keypoint
                                dell'indice in una coda <i>FIFO</i> che mantiene i punti dei 20 frame
                                precedenti.</br></br>
                                Anche in questo caso i dati estratti dai Landmarks vengono preprocessati, prima di
                                inserirli nel file di dataset.</br>

                                Utilizzando i tasti numerici "0" e "1", i Keypoints verranno aggiunti al file
                                <code>assets/dataset/keypoint_history.csv</code></br></br>

                                Eseguendo lo script con argomento <i>mode 2</i> si avrà il seguente:
                                </br></br>
                                <img class="img-fluid  profile-image img-responsive pull-left"
                                    src="./assets/img/hand-gesture.png"> </br>

                            </p>



                        </div>

                        <h3 class="h3-heading"> Training</h3>
                        <div class="content">
                            <p>Il training delle reti e di conseguenza la creazione dei due modelli, ha richiesto la
                                creazione di un <i>Jupiter Notebook</i> per ciscun datatset;</br></br>
                                <code>neuralnetwork/hand_classificator.ipynb</code> per quanto riguarda gli
                                <i>hand sign</i>.</br>
                                <code>neuralnetwork/hand_history_classificator.ipynb</code> per quanto
                                riguarda le <i>hand gesture</i>.</br></br>
                                Il dataset per gli <i>hand sign</i> è stato diviso in:
                            </p>
                            <ul>
                                <li>60% training;</li>
                                <li>20% test;</li>
                                <li>20% validation.</li>
                            </ul>
                            <iframe class="w-100" style="height: 50vh;"
                                src="./assets/plot/data-plot.html"></iframe></br>
                            Il modello della rete vine creato nel seguente modo:</br></br>
                            <div class="row">

                                <pre>
                                    <code class="python">
model = tf.keras.models.Sequential([
    tf.keras.layers.Input((21 * 2, )),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(20, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax'),
])
                                    </code>
                                </pre>
                            </div>

                            <div class="row">
                                <img class="model" src="./assets/img/model_hand_sign.png">
                            </div>
                            </br>Anche il dataset per le <i>hand gesture</i> è stato diviso in:
                            <ul>
                                <li>60% training;</li>
                                <li>20% test;</li>
                                <li>20% validation.</li>
                            </ul>
                            <iframe class="w-100" style="height: 50vh;"
                                src="./assets/plot/data-plot2.html"></iframe></br>

                            Il modello della rete vine creato nel seguente modo:</br></br>

                            <pre><code class="python"> 
model = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(TIME_STEPS * DIMENSION, )),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(24, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='relu'),
    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')
])
                                </code></pre>

                            <div class="row">
                                <img class="model" src="./assets/img/model_hand_gesture.png">
                            </div>
                        </div>
                        </br></br>
                        <h3 class="h3-heading"> Interfaccia grafica </h3>
                        <div class="content">
                            <p>
                                L'interfaccia grafica è stata realizzata mediante l'uso congiunto di due
                                librerie , <strong><i>Kivy</i></strong> e <strong><i>KivyMD</i></strong>. Lo scopo
                                finale della sua realizzazione
                                è interagire con arduino in modo semplice e veloce inglobando gli output dei precedenti
                                passaggi,
                                in particolare i due modelli risultanti dall' addestramento delle rispettive reti
                                neurali.</br></br> I componenti che la costituiscono sono:

                            </p>
                            <ul>
                                <li>
                                    Una <i>App Bar</i> che mostra il nome dell'applicazione;
                                </li>
                                <li>
                                    un <i>Tab Menu</i> che mostra le due modalità di funzionamento;
                                </li>
                                <li>
                                    un <i>modello di Arduino</i> in una configurazione compatibile con il dispositivo
                                    fisico per mostrare un feedback della conversione;
                                </li>
                                <li>
                                    uno <i>spazio per la camera</i> che mostra il video della webcam;
                                </li>
                                <li>
                                    un <i> Flat Button</i> per richiedere l'accensione della webcam;
                                </li>
                                <li>
                                    un <i> Flat Button</i> per richiedere la connessione con il dispositivo
                                    Arduino;
                                </li>
                                <li>
                                    un <i> Flat Button</i> per richiedere l'avvio della classificazione.
                                </li>
                            </ul>
                            Il risultato finale della disposizione degli elementi appena elencati è il seguente: </br>
                            </br>
                            <div class="row">
                                <img src="./assets/img/home_page.png" , />
                            </div>
                            <h3 class="h3-heading"> Tab - Recognition and Detection with Arduino</h3>
                            <p>
                                In questa tab viene mostrato il funzionamento congiunto dell'applicazione con Arduino. 
                                Quindi, in successione, mediante i bottoni è possibile avviare la web cam, connettersi al
                                dispositivo fisico ed iniziare la fase di Detection sfruttando i modelli creati nelle fasi precendenti.</br></br> 
                                Di seguito viene mostrato il riconoscimento dell'hand sign <strong><i>Finger 2</i></strong> che accende 
                                il led rosso, inoltre in basso è possibile visionare la percentuale di previsione effettuata dal modello.</br>
                            </p>
                            <div class="row">
                                <img  src="./assets/img/templateFinger2.png" , />
                            </div>
                            <h3 class="h3-heading"> Tab - Recognition</h3>
                            <p>
                                In questa tab viene mostrato il funzionamento della sola <i>Detection</i> e <i>Classificazione</i>, congiunto con alcuni <i>pre-processing</i>
                                dell'immagine.</br></br>
                                In particolare, il bottone <i>grayscale camera</i> trasforma in scala di grigi l'immagine acquisita inizialmente dalla webcam ed effettua la classificazione.
                                <div class="row">
                                    <img  src="./assets/img/finger2Grayscale.png" , />
                                </div>
                            </p>
                            <p>
                                Invece, il bottone <i>Background camera</i> consente di effettuare la sottrazione del background nell'immagine nei limiti imposti dall'ambiente
                                in cui ci troviamo.
                                <div class="row">
                                    <img  src="./assets/img/finger2Backgr.png" , />
                                </div>
                            </p>
                        </div>
                    </div>
                </section>

                <!-- Implementazione e codice -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="dataset"></a>Implementazione e Codice</h2>
                        <div class="content">
                            <h3 class="h3-heading"> Implementazione</h3>
                            <div class="content">
                                <p>
                                    Le tecnologie software utilizzate per implementare il progetto sono state:
                                <ul>
                                    <li>Python 3</li>
                                    <ul>
                                        <li>
                                            Mediapipe
                                        </li>
                                        <li>
                                            Tensorflow lite
                                        </li>
                                        <li>
                                            Pandas
                                        </li>
                                        <li>
                                            Scikit-learn
                                        </li>
                                        <li>
                                            Matplotlib
                                        </li>
                                        <li>
                                            OpenCV
                                        </li>
                                    </ul>
                                </ul>
                                </ul>
                                </ul>
                                Framework per l'interfaccia grafica
                                <ul>
                                    <li>Kivy</li>
                                    <li>KivyMD</li>
                                </ul>
                                </ul>
                                </ul>
                                Dispositivo Hardware
                                <ul>
                                    <li>Arduino UNO</li>
                                </ul>
                                </p>

                                <h3 class="h3-heading"> Codice sorgente</h3>
                                <div class="content">
                                    <p>
                                        <a href="https://github.com/vinrus/progetto-visione" target="_blank">Link
                                            repository Github</a>
                                    </p>

                                </div>
                            </div>
                </section>

                <!-- Dataset -->
                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="dataset"></a>Dataset</h2>
                        <div class="content">
                            <p>Il primo dataset è composto nel seguente modo:</p>
                            <table class="table table-striped table-hover table-bordered border-dark ">
                                <thead class="table-primary table-bordered border-dark">
                                    <tr class="">
                                        <th>Classe</th>
                                        <th>n° di dati</th>
                                    </tr>
                                </thead>
                                <tbody class="">
                                    <tr>
                                        <td>Palm open</td>
                                        <td>3000</td>
                                    </tr>
                                    <tr>
                                        <td>Fist (palm closed)</td>
                                        <td>3000</td>
                                    </tr>
                                    <tr>
                                        <td>Index</td>
                                        <td>3000</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 2</td>
                                        <td>3000</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 3</td>
                                        <td>3000</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 4</td>
                                        <td>3000</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <div class="content">
                            <p>Il secondo dataset è composto nel seguente modo:</p>
                            <table class="table table-striped table-hover table-bordered border-dark ">
                                <thead class="table-primary table-bordered border-dark">
                                    <tr class="">
                                        <th>Classe</th>
                                        <th>n° di dati</th>
                                    </tr>
                                </thead>
                                <tbody class="">
                                    <tr>
                                        <td>Clockwise</td>
                                        <td>12000</td>
                                    </tr>
                                    <tr>
                                        <td>Counter clockwise</td>
                                        <td>12000</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                </section>

                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading"><a id="training"></a>Risultati</h2>
                        <div class="content">


                            <h3>Risultati qualitativi</h3>
                            <p>
                                In questa sezione verranno presentati due video per la dimostrazione del funzionamento di Arduino.</br></br> Il primo 
                                mostra il funzionamento della sincronizzazione con gli hand sign. Dall'interfaccia grafica, descritta nelle sezioni precendenti,
                                vengono riconosciuti gli hand sign e successivamente vengono trasformati in comandi mandati in input ad Arduino, in particolare
                                è possibile notare come i led vengono accesi in sequenza, simultaneamente, oppure spenti.</br></br> 
                                Il successivo, invece, mostra la seconda modalità di funzionamento incentrata sulle due gesture implementate, ovvero
                                <i>Clockwise</i> per una rotazione in senso orario di 180° del servo motore, mentre la seconda, <i>Counter clockwise</i>, per una rotazione
                                di 180° in senso antiorario.</br></br> Sul servo motore è stata posta una freccia per facilitare l'osservazione del movimento. In fase di boot, siccome 
                                la posizione iniziale del servo motore, di default, è pari a 90°, l'Arduino per eseguire la gesture <i>clockwise</i> imposta il servo motore all'angolo 0°
                                per poi raggiungere i 180°. Da qui partirà poi la seconda gesture, ovvero <i>counter clockwise</i>, in cui dalla posizione iniziale 
                                si procederà a ritroso per raggiungere gli 0°. Terminato il movimento, il servo motore viene riportato nella sua posizione di default, ovvero 90°.
                            </br></br>
                                <video width="680" height="400" controls autoplay>
                                    <source src="./assets/video/HandSignArduino.mp4" type=video/mp4>
                                </video>
                                </br>
                                

                                <video width="680" height="400" controls autoplay>
                                    <source src="./assets/video/HandGestureArduino.mp4" type=video/mp4>
                                </video>
                            </p>
                        </br>


                            <h3>Risultati quantitativi</h3>
                            <p>Per valutare le performance del modello, è stata utilizzata come metrica la
                                <i>F1-score</i>.</br>
                                Questa riassume le prestazioni predittive del modello utilizzando a sua volta due
                                ulteriori metriche:</br>
                                <i>Precision</i> e <i>Recall</i>.</br></br>
                                La <i>precision</i> è il rapporto tra il numero delle previsioni corrette di un evento
                                (classe) sul totale delle volte
                                che il modello lo prevede. Quando un modello è preciso per una classe, ogni volta che
                                prevede l'evento sbaglia raramente.</br></br>
                                La <i>recall</i> misura la sensibilità del modello. E' il rapporto tra le previsioni
                                corrette per una classe sul totale dei casi
                                in cui si verifica effettivamente.
                            </p>
                            <p>Per definizione, <i>F1-score</i> è la media aronica di <i>Precision</i> e <i>Recall</i>
                                definita come:</br>
                                \[ \text{F1-score} = 2 \times \frac{Precision \times Recall}{Precision + Recall}\] </br>

                                Questa formula può essere scritta in modo equivalente come:

                                \[\text{F1-score} = \frac{2}{\frac{1}{Precision} + \frac{1}{Recall}}\] </br>

                                F1-score tiene conto sia di <i>precision</i> che di <i>recall</i>, il che significa che
                                tiene in considerazione sia dei
                                <i>FP</i> (false positive) che dei <i>FN</i>(false negative), essendo un valore compreso
                                tra 0 e 1, più
                                è vicino a 1, migliore è il modello.</br></br>

                                Per rappresentare tali risultati è stata creata la matrice di confusione come ulteriore metrica nella quale
                                ogni riga
                                rappresenta i valori predetti, mentre ogni colonna rappresenta i valori reali.
                                L'elemento sulla colonna
                                j è il numero di casi in cui il classificatore ha classificato la classe "vera" j come
                                classe i. Attraverso
                                questa matrice è osservabile se vi è "confusione" nella classificazione di diverse
                                classi. Nella tabella relativa vengono rappresentati, per ogni classe, i diversi valori delle metriche.
                                </br>
                                In aggiunta, sono stati riportati i grafici relativi a <i> Loss </i> e <i> Accuracy</i> per i dati
                                di Train e di Validation.</br>


                                

                            </p>
                            <p>
                                Per quando riguarda il modello per la classificazione degli <i>Hand Sign</i>
                                abbiamo:</br>
                            <div class="row">
                                <img class="d-flex justify-content-center" src="./assets/img/confusionMatrix1.png">
                            </div></br></br>


                            <table class="table table-striped table-hover table-bordered border-dark ">
                                <thead class="table-warning table-bordered border-dark">
                                    <tr class="">
                                        <th>Classe</th>
                                        <th>Precision</th>
                                        <th>Recall</th>
                                        <th>F1-score</th>
                                    </tr>
                                </thead>
                                <tbody class="">
                                    <tr>
                                        <td>Palm open</td>
                                        <td>1.0</td>
                                        <td>0.99</td>
                                        <td>0.99</td>
                                    </tr>
                                    <tr>
                                        <td>Fist (palm closed)</td>
                                        <td>1.0</td>
                                        <td>1.0</td>
                                        <td>1.0</td>
                                    </tr>
                                    <tr>
                                        <td>Index</td>
                                        <td>0.97</td>
                                        <td>1.0</td>
                                        <td>0.99</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 2</td>
                                        <td>0.99</td>
                                        <td>0.97</td>
                                        <td>0.98</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 3</td>
                                        <td>1.0</td>
                                        <td>0.99</td>
                                        <td>1.0</td>
                                    </tr>
                                    <tr>
                                        <td>Finger 4</td>
                                        <td>0.99</td>
                                        <td>1.0</td>
                                        <td>1.0</td>
                                    </tr>
                                </tbody>
                            </table>
                            </p>
                            <p>
                                <iframe class="w-100" style="height: 50vh;"
                                    src="./assets/plot/train1.html"></iframe></br>
                                <iframe class="w-100" style="height: 50vh;"
                                    src="./assets/plot/validation1.html"></iframe></br>
                            </p>

                            <p>
                                Per quando riguarda il modello per la classificazione delle <i>Hand Gesture</i>
                                abbiamo:</br>



                            <div class="row">
                                <img class="d-flex justify-content-center" src="./assets/img/confusionMatrix2.png">
                            </div>
                            </br></br>

                            <table class="table table-striped table-hover table-bordered border-dark ">
                                <thead class="table-warning table-bordered border-dark">
                                    <tr class="">
                                        <th>Classe</th>
                                        <th>Precision</th>
                                        <th>Recall</th>
                                        <th>F1-score</th>
                                    </tr>
                                </thead>
                                <tbody class="">
                                    <tr>
                                        <td>Clockwise</td>
                                        <td>0.99</td>
                                        <td>1.0</td>
                                        <td>1.0</td>
                                    </tr>
                                    <tr>
                                        <td>Counter Clockwise</td>
                                        <td>1.0</td>
                                        <td>0.99</td>
                                        <td>1.0</td>
                                    </tr>
                                </tbody>
                            </table>
                            </p>
                            <p>
                                <iframe class="w-100" style="height: 50vh;"
                                    src="./assets/plot/train2.html"></iframe></br>
                                <iframe class="w-100" style="height: 50vh;"
                                    src="./assets/plot/validation2.html"></iframe></br>
                            </p>
                        </div>
                        <!--//content-->
                    </div>
                    <!--//section-inner-->
                </section>
                <!--//section-->


                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading">Appendice - immagini aggiuntive</h2>
                        <div class="content">
                            <p>
                                <div class="row">
                                    <img  src="./assets/img/appendix1.png" , />
                                </div>
                            </p>
                            <p>
                                <div class="row">
                                    <img  src="./assets/img/appendix2.png" , />
                                </div>
                            </p>
                            <p>
                                <div class="row">
                                    <img  src="./assets/img/appendix3.png" , />
                                </div>
                            </p>
                            <p>
                                <div class="row">
                                    <img  src="./assets/img/appendix4.png" , />
                                </div>
                            </p>
                            <p>
                                <div class="row">
                                    <img  src="./assets/img/appendix5.png" , />
                                </div>
                            </p>
                        </div>
                    </div>
                </section>

            </div>
            <!--//primary-->

            <div class="secondary col-md-4 col-sm-12 col-xs-12">
                <aside class="info aside section">
                    <div class="section-inner">
                        <h2 class="heading">Autori</h2>
                        <div class="content">
                            <p>Andrea D'Acunto, 61006</p>
                            <p>Marco D'Emilio, 59973 </p>
                            <p>Vincenzo Russo, 61005</p>
                        </div>
                        <!--//content-->
                    </div>
                    <!--//section-inner-->
                </aside>
                <!--//aside-->


                <aside class="blog aside section">
                    <div class="section-inner">
                        <h2 class="heading">Riferimenti</h2>
                        <div class="content">
                            <div class="item">
                                <a href="https://google.github.io/mediapipe/" target="_blank">MediaPiepe</a>
                            </div>
                            <div class="item">
                                <a href="https://www.arduino.cc" target="_blank">Arduino</a>
                            </div>
                            <div class="item">
                                <a href="https://kivy.org" target="_blank">Kivy</a>
                            </div>
                        </div>
                        <!--//content-->
                    </div>
                    <!--//section-inner-->
                </aside>
                <!--//section-->

            </div>
            <!--//secondary-->
        </div>
        <!--//row-->
    </div>
    <!--//masonry-->

    <!-- ******FOOTER****** -->
    <footer class="footer">
        <div class="container text-center">
            <small class="copyright">This template adapted from <a href="http://themes.3rdwavemedia.com/"
                    target="_blank">3rd Wave Media</a></small>
        </div>
        <!--//container-->
    </footer>
    <!--//footer-->

</body>

</html>